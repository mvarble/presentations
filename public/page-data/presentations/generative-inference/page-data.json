{"componentChunkName":"component---src-layouts-presentation-tsx-content-file-path-mnt-shared-storage-dropbox-dev-websites-presentations-content-presentations-generative-inference-talk-mdx","path":"/presentations/generative-inference","result":{"data":{"presentation":{"title":"Generative Inference","slug":"/generative-inference","date":"2022-07-28T16:30:00.000Z","width":960,"height":700,"fragmentsBySlide":[0,3,6,3,6,11,4,6,0,3,3,66,0,0]}},"pageContext":{"id":"8f2fdddd-2050-55b9-93a2-7fab6b47c0be","frontmatter":{"title":"Generative Inference","slug":"/generative-inference","date":"2022-07-28T16:30:00.000Z","description":"Perhaps one of the most enlightening moments in studying probability and statistics is identifying a distinction between the two terms, “probability” and “statistics.” The concept of a “generative model” is one in which the indeterminism of our measurements is understood through a causal structure which may be simulated on a computer. Studying and simulating these models allows one to quickly build an intuition with distinguishing between probability and statistics. Once establishing the intuition of generative models, I explain different inference algorithms one may employ. These may be seen as having a machine learning 'flavor', in the sense that models may be parameterized through complex maps that are chosen via variational methods and may only be understood through their generation."}}},"staticQueryHashes":[]}